from typing import Any
import numpy as np
import matplotlib.pyplot as plt

class OtsuThresholding:
    """
    OTSU's Algorithm
    Used to find the best global Threshold T between classes.
    Where the Image is composed of light objects on a dark background
    An alternative to the Bayesian approach (used with gaussian distributions, minimizing the avg sq error incurred in assigning pixels to two or more groups)

    Idea.
    Split the pixels into 2 classes (Background or Foreground) as well separatad as possible.
    Maximize the between-class variance. (properly thresholded classes should be distinct with respect to the intensity values of their pixelse and conversely, that a threshold giving the best separation between classes would be the best threshold)
    A good threshold should separate pixels into tight clusters
    Let  ğ¿={0,1,..ğ¿âˆ’1}  denote the set of L distinct integer intensity levels in a digital image of size M x N
    Let  ğ‘›ğ‘–  denote the number of pixels with intensity i. The total number, NM of pixels in the image is  ğ‘€ğ‘=ğ‘›0+ğ‘›1+...+ğ‘›ğ¿âˆ’1 
    The normalized histogram has components  ğ‘ğ‘–=ğ‘›ğ‘–ğ‘€ğ‘  where  âˆ‘ğ‘ğ‘–=1 

    Given a threshold  ğ‘‡ , define two classes.
    ğ¶1={(ğ‘¥,ğ‘¦)|ğ¼(ğ‘¥,ğ‘¦)<=ğ‘‡} 

    ğ¶2={(ğ‘¥,ğ‘¦)|ğ¼(ğ‘¥,ğ‘¦)>ğ‘‡} 

    Compute the normalized histogram of the input image. Denote its components by  ğ‘ğ‘–={0,1,...,ğ¿âˆ’1} 

    Compute the cummulative sums,  ğ‘ƒ1(ğ‘‡)=âˆ‘ğ‘‡ğ‘–=0ğ‘ğ‘–  = P(I(x,y) <= T) for  0<ğ‘‡<ğ¿âˆ’1 

    Compute the cummulative mean,  ğ‘š(ğ‘‡)=âˆ‘ğ‘‡ğ‘–=0ğ‘–ğ‘ğ‘– 

    Compute the global mean of the entire image,  ğ‘šğº(ğ‘‡)=âˆ‘ğ¿âˆ’1ğ‘–=0ğ‘–ğ‘ğ‘– 

    =ğ‘š(ğ‘‡=ğ¿âˆ’1) 

    Compute the between-class variance term,
    ğœ2ğµ(ğ‘‡)=ğ‘ƒ1(ğ‘š1âˆ’ğ‘šğº)2+ğ‘ƒ2(ğ‘š2âˆ’ğ‘šğº)2=ğ‘ƒ1ğ‘ƒ2(ğ‘š1âˆ’ğ‘š2)2=ğ‘šğºğ‘ƒ1âˆ’ğ‘šğ‘ƒ1(1âˆ’ğ‘ƒ1) 

    Note 1:
    ğ‘ƒ1ğ‘š1+ğ‘ƒ2ğ‘š2=ğ‘šğº 
    ğ‘ƒ1+ğ‘ƒ2=1 

    ğ‘š1(ğ‘‡)=âˆ‘ğ‘‡ğ‘–=0ğ‘–ğ‘ƒ(ğ‘–|ğ‘–âˆˆğ‘1)   =âˆ‘ğ‘‡ğ‘–=0ğ‘–ğ‘ƒ(ğ‘–âˆˆğ‘1|ğ‘–)î„»î„¼î…€î…Šî…Š=1ğ‘ƒ(ğ‘–)ğ‘ƒ(ğ‘1)=1ğ‘ƒ1(ğ‘‡)âˆ‘ğ‘‡ğ‘–=0ğ‘–ğ‘ğ‘– 
    ğ‘š2(ğ‘‡)=1ğ‘ƒ2(ğ‘‡)âˆ‘ğ¿âˆ’1ğ‘–=ğ‘‡+1ğ‘–ğ‘ğ‘– 

    Note 2:
    The farther the means  ğ‘š1  and  ğ‘š2  are, the greater the  ğœ2ğµ  variance will be. Implying that the between class variance is a measure of separability between classes.

    Obtain the Otsu's threshold  ğ‘‡âˆ— . If the maximum is not unique, obtain  ğ‘‡âˆ—  by averaging values of  ğ‘‡  corresponding to the various maxima detected.
    ğ‘‡âˆ—=ğ‘ğ‘Ÿğ‘”ğ‘šğ‘ğ‘¥ğ‘‡âˆˆ[0,ğ¿âˆ’1] ğœ2ğµ(ğ‘‡) 

    So Otsu's criterion is to maximize the between-class variance
    Compute the global variance  ğœ2ğº=âˆ‘ğ¿âˆ’1ğ‘–=0(ğ‘–âˆ’ğ‘šğº)2ğ‘ğ‘– 
    Compute the separability measure  ğœ‚=ğœ2ğµ/ğœ2ğº 
    The measure  ğœ2ğ‘/ğœ2ğ‘  is a good measure of separability
    """
    def __init__(self):
        pass
    def __call__(self):
        pass

if __name__ == '__main__':
    import numpy as np
    import matplotlib.pyplot as plt
    import urllib.request
    plt.style.use('dark_background')


    url = "https://github.com/leinaxd/NOTES/raw/main/digital_image_processing/notebooks/background.jpg"
    with urllib.request.urlopen(url) as url:
        img = plt.imread(url, format='jpg')
    plt.imshow(img)
    plt.axis('off')

    print(img.shape)

    r_mask = img[:, :, 0]
    g_mask = img[:, :, 1]
    b_mask = img[:, :, 2]

    #turn image to gray
    g_img = r_mask*0.2989 + g_mask*0.5870 + b_mask*0.1140
    u_img = np.uint8(g_img)
    nbins = 50 #@param {'type':'integer'}

    #Algorithm
    # step 1
    h_im, p_im = np.histogram(g_img.flatten(), bins=nbins,density=True, range=[0,255])
    w_bar = p_im[1:]-p_im[:-1] #width of each histogram bar
    intensities = np.zeros_like(p_im) #x axis
    intensities[1:] = np.cumsum(w_bar)
    p_i = np.zeros_like(p_im) #adds zero prob to intensity < 0
    p_i[1:] = h_im * w_bar #prob = area of each histogram bar

    # print(len(h_im))
    # step 2
    P_1 = np.cumsum(p_i)
    # plt.hist(g_img.flatten(), density=True, bins=nbins, alpha=0.2)

    #step 3
    m = np.cumsum(intensities*p_i)

    #step 4
    m_G = m[-1]

    #step 5
    sigma_B = (m_G * P_1-m)**2/(1E-10+P_1*(1-P_1))

    #step 6
    ix_star = np.argmax(sigma_B)
    T_star  = intensities[ix_star]

    #step 7
    sigma_G = np.sum((intensities-m_G)**2 * p_i)

    #step 8
    eta = sigma_B[ix_star]/sigma_G

    #Others
    m_1 = m[ix_star]/P_1[ix_star]
    m_2 = (m_G - m[ix_star])/(1-P_1[ix_star])

    im_1 = (g_img > T_star)*g_img
    im_2 = (g_img <=T_star)*g_img
    im_1 = np.uint8(im_1)
    im_2 = np.uint8(im_2)

    fig, ax = plt.subplots(2,3, figsize=(15,10))
    ax[0][0].bar(p_im[:-1], h_im, align='edge', width=1*w_bar[0])
    ax[0][0].set_title('$p_i$: PDF')
    ax[0][0].text(T_star-15, 0.006, 'T*',color='r')
    ax[0][0].axvline(T_star, color='r')
    ax[0][0].text(m_G+5, 0.008, 'm_G',color='g')
    ax[0][0].axvline(m_G, color='g', linestyle='--')
    ax[0][0].text(m_1+5, 0.008, 'm_1',color='g')
    ax[0][0].axvline(m_1, color='g', linestyle='--')
    ax[0][0].text(m_2+5, 0.008, 'm_2', color='g')
    ax[0][0].axvline(m_2, color='g', linestyle='--')


    ax[0][1].plot(intensities, P_1)
    ax[0][1].set_title('$P_1$: cummulative distribution')

    ax[0][2].plot(intensities, sigma_B/sigma_G)
    ax[0][2].set_title('$\eta = \sigma^2_B/\sigma^2_G$')
    ax[0][2].text(T_star-15, 0.006, 'T*',color='r')
    ax[0][2].axvline(T_star, color='r')

    ax[1][0].imshow(g_img, cmap='gray')
    ax[1][0].axis('off')
    ax[1][0].set_title('original');

    ax[1][1].imshow(im_1, cmap='gray')
    ax[1][1].set_title(f'Background');
    ax[1][1].axis('off');

    ax[1][2].imshow(im_2, cmap='gray')
    ax[1][2].set_title(f'Foreground');
    ax[1][2].axis('off');